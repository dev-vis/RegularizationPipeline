{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "from collections import defaultdict\n",
    "import string \n",
    "import random \n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'amazon_reviews_us_Gift_Card_v1_00.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = gzip.open(path, 'rt', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = header.strip().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        word_count[w] +=1\n",
    "counts = [(word_count[w], w) for w in word_count]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [x[1] for x in counts[:100]]\n",
    "word_id = dict(zip(words, range(len(words))))\n",
    "word_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0] * len(words)\n",
    "    r = ''.join([c for c in datum['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[word_id[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['star_rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "X_train = X[:N//2] # splitting the dataset by 50%, 25% and 25%\n",
    "X_valid = X[N//2:3*N//4]\n",
    "X_test = X[3*N//4:]\n",
    "y_train = y[:N//2]\n",
    "y_valid = y[N//2:3*N//4]\n",
    "y_test = y[3*N//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149086, 74543, 37271, 37272)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    differences = [(a-b)**2 for (a,b) in zip(predictions, y)]\n",
    "    return sum(differences)/len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model for a range of regularization parameters\n",
    "best_model = None\n",
    "best_MSE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.01 training---validation error = 0.5301094588998126---0.5418490681191773\n",
      "lambda = 0.1 training---validation error = 0.5301094590024961---0.5418488082281372\n",
      "lambda = 1 training---validation error = 0.5301094692676435---0.5418462189102249\n",
      "lambda = 10 training---validation error = 0.5301104943077638---0.541821283478632\n",
      "lambda = 100 training---validation error = 0.5302115624881009---0.5416662305952524\n"
     ]
    }
   ],
   "source": [
    "for lamb in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = linear_model.Ridge(lamb, fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    mse_train = MSE(model, X_train, y_train)\n",
    "    mse_valid = MSE(model, X_valid, y_valid)\n",
    "    \n",
    "    print('lambda = ' + str(lamb) + ' training---validation error = '+str(mse_train) + '---' + str(mse_valid))\n",
    "    if not best_model or mse_valid < best_MSE:\n",
    "        best_model = model\n",
    "        best_MSE = mse_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error = 0.524367932606683\n"
     ]
    }
   ],
   "source": [
    "mse_test = MSE(best_model, X_test, y_test)\n",
    "print('test error = '+ str(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
